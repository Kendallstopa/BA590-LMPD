{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Stop Activity Result: Citation vs. Warning \n",
    "\n",
    "#### BA 590 Capstone: Business Analytics Applications - Proposal\n",
    "#### Proposed By: Kendall Stopa\n",
    "1.\tProject Background/Motivation\n",
    "    - Millions of Americans are stopped each year due to traffic violations. There are many reasons as to why one would be pulled over such as speeding, using a cellphone, not wearing a seatbelt, etc. What I want to know is what dictates the end result of a traffic stop? \n",
    "\n",
    "2.\tProblem Statement/Statement of Work\n",
    "    - What features are most strongly associated with an activity result of a citation or a warning?  \n",
    "\n",
    "3.\t Preliminary Results/Exploratory Data Analysis (see figures on page 2-3)\n",
    "    - The dataset that I will be using is information available in the Louisville Metro Police Department Vehicle Stops Database for 2015 – 2018, obtained from Data.gov. There are 111,582 rows and 18 columns in this dataset. \n",
    "\n",
    "4.\tPlanning Timeline with Milestones (start and end dates) for each phase of the project\n",
    "    - EDA and Preprocessing &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Start: 5/18 – End: 5/21\n",
    "    - Modeling &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Start: 5/22 – End: 6/01\n",
    "    - Geo coding &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Start: 6/03 – End: 6/15\n",
    "    - Concluding Project &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Start: 6/17 – End: 6/23\n",
    "\n",
    "5.\tSummary of expected results\n",
    "    - The expected result of this analytical project is to build multiple classification models commonly used machine learning algorithms to predict the activity result one would receive during a traffic stop and determine the most accurate predictive model to use for this data. To see which features of a traffic stop have the largest impact on predicting the activity result of a traffic stop I will be using feature selection. I will also be geocoding the location of each traffic stop to explore this data spatially and create a visualization where the activity result was given. \n",
    "\n",
    "\n",
    "6.\t Signoff from your advisor and your subject matter expert: \n",
    "    - Dr. Christopher Huntly\n",
    "    - Mike Garvey (Alumni Class of ’89, 20 years Rockland County Police Department)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages we know we will need upfront\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import iqr\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading imputed data to df from CSV WorkingDataFrame\n",
    "df = pd.read_csv('BA590-LMPD/LMPDStopsDatFrame.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ACTIVITY RESULTS'].value_counts().plot.bar(title=\"Freq dist of Activity Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OFFICER_GENDER'].value_counts().plot.bar(title=\"Freq dist of Officer Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DRIVER_GENDER'].value_counts().plot.bar(title=\"Freq dist of Driver Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OFFICER_AGE_RANGE'].value_counts().plot.bar(title=\"Freq dist of Officer Age Range \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DRIVER_AGE_RANGE'].value_counts().plot.bar(title=\"Freq dist of Officer Driver Range \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation & Cleaning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing values for each column using its own most frequent value\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataset, to recode values to be numerical for data analysis. \n",
    "df2 = df.copy(deep=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df2.filter(['TYPE_OF_STOP', 'OFFICER_GENDER', 'DRIVER_GENDER',\n",
    "       'WAS_VEHCILE_SEARCHED'])\n",
    "X2 = df2.filter(['ID', 'CITATION_CONTROL_NUMBER', 'ACTIVITY_DATE', 'ACTIVITY_TIME', 'ACTIVITY_LOCATION', \n",
    "        'ACTIVITY_DIVISION', 'ACTIVITY_BEAT', 'OFFICER_AGE_RANGE', 'DRIVER_AGE_RANGE', 'REASON_FOR_SEARCH'])\n",
    "y = df2.iloc[:, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.get_dummies(X1)\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([X1, X2], axis=1, sort=False)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing year with 2025 to 2015.. assuming a typo \n",
    "df_concat['ACTIVITY_DATE'] = df_concat['ACTIVITY_DATE'].str.replace(\"2025\",\"2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting time column data type to Datetime64\n",
    "df_concat['ACTIVITY_DATE']=df_concat['ACTIVITY_DATE'].astype('Datetime64',copy=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new column of just the year of the activity date\n",
    "df_concat['ACTIVITY_MONTH_YEAR'] = df_concat['ACTIVITY_DATE'].dt.strftime('%m/%y')\n",
    "df_concat['ACTIVITY_MONTH'] = df_concat['ACTIVITY_DATE'].dt.strftime('%m')\n",
    "df_concat['ACTIVITY_DAY'] = df_concat['ACTIVITY_DATE'].dt.strftime('%d') \n",
    "df_concat['ACTIVITY_YEAR'] = df_concat['ACTIVITY_DATE'].dt.strftime('%y')\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['ACTIVITY_YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new column of just the year of the activity date\n",
    "df_concat['ACTIVITY_MONTH_YEAR'] = df_concat['ACTIVITY_DATE'].dt.strftime('%m/%y')\n",
    "df_concat['ACTIVITY_MONTH'] = df_concat['ACTIVITY_DATE'].dt.strftime('%m')\n",
    "df_concat['ACTIVITY_DAY'] = df_concat['ACTIVITY_DATE'].dt.strftime('%d') \n",
    "df_concat['ACTIVITY_YEAR'] = df_concat['ACTIVITY_DATE'].dt.strftime('%y')\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing column Activity_Time from 24 hour to 12 hour \n",
    "import datetime\n",
    "times = df_concat['ACTIVITY_TIME']\n",
    "df_concat['ACTIVITY_TIME']=[datetime.datetime.strptime(time, \"%H:%M:%S\").strftime(\"%I:%M %p\") for time in times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing 'over 60' with age range 61-70, and 'UNDER 16' with age range 15-10\n",
    "df_concat = df_concat.replace({'OFFICER_AGE_RANGE': {'OVER 60': '61 - 70'}})\n",
    "df_concat = df_concat.replace({'DRIVER_AGE_RANGE': {'OVER 60': '61 - 70', 'UNDER 16': '15 - 10'}})\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using split_mean() function to split age ranges to calculate mean, added columns'OFFICER_AGE_MEAN' & 'DRIVER_AGE_MEAN'\n",
    "def split_mean(x):\n",
    "    split_list = x.split('-')\n",
    "    mean = (float(split_list[0])+float(split_list[1]))/2\n",
    "    return mean\n",
    "\n",
    "df_concat['OFFICER_AGE_MEAN'] = df_concat['OFFICER_AGE_RANGE'].apply(lambda x: split_mean(x))\n",
    "df_concat['DRIVER_AGE_MEAN'] = df_concat['DRIVER_AGE_RANGE'].apply(lambda x: split_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['ACTIVITY_YEAR'].value_counts().plot.bar(title=\"Annual Number of Stops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Age in the Dataset \n",
    "df_concat['OFFICER_AGE_MEAN'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Age in the Dataset \n",
    "df_concat['DRIVER_AGE_MEAN'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sklearn package to run logistic regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent and independent variables\n",
    "X = X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test spilt on our data having test size be 25% of the main data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the target variable is not 50/50 we are oversampling so that the target option (Churn, Yes or No) is even\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=2019)\n",
    "X_train_resample, y_train_resample = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# fit the model with data\n",
    "logreg = logreg.fit(X_train_resample,y_train_resample)\n",
    "\n",
    "#\n",
    "y_pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Accuracy \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1_Score:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "#print(\"AUC:\",roc_auc_score(y_test, y_pred)) *** This does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive Feature Elimination \n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(1, X1.shape[1]+1):\n",
    "    print(i)\n",
    "    # create a base classifier used to evaluate a subset of attributes\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    # create the RFE model and select 3 attributes; Target Variable Y2\n",
    "    rfe = RFE(model, i)\n",
    "    rfe = rfe.fit(X1, y)\n",
    "    # summarize the selection of the attributes\n",
    "    print('Model with the best', i, 'features')\n",
    "    print(dict(zip(X1.columns, rfe.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Decision Tree Classifier  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create Decision Tree Classifier Object \n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train_resample, y_train_resample)\n",
    "\n",
    "# Predict the response for test dataset \n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1_Score:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "#print(\"AUC:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kneigh = KNeighborsClassifier()\n",
    "kneigh = kneigh.fit(X_train_resample, y_train_resample)\n",
    "y_pred = kneigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1_Score:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "#print(\"AUC:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ADA = AdaBoostClassifier(n_estimators=70, random_state=2019)\n",
    "ADA = ADA.fit(X_train_resample, y_train_resample)\n",
    "y_pred = ADA.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1_Score:\",f1_score(y_test, y_pred, average='weighted'))\n",
    "#print(\"AUC:\",roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=2019)\n",
    "X_resample, y_resample = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_valid_ex.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "features, targets = X_resample, y_resample\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(solver='liblinear')))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "#models.append(('SVC', SVC(kernel='rbf', gamma='auto')))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "models.append(('AdaClassifier', AdaBoostClassifier()))\n",
    "#models.append(('RandomForest', RandomForestClassifier(n_estimators=100)))\n",
    "\n",
    "\n",
    "# KFold with 'stratify' option\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv, scoring='roc_auc')\n",
    "    print(\"Model:{0}, Score: AUC={1:0.5f}, var={2:0.5f}\".format(\n",
    "        name,\n",
    "        score.mean(),\n",
    "        score.var()\n",
    "        )\n",
    "    )\n",
    "cv1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=2019)\n",
    "for name, model in models:\n",
    "    score = cross_val_score(model, features, targets, cv=cv1, scoring='f1')\n",
    "    print(\"Model:{0}, Score: F1={1:0.5f}, var={2:0.5f}\".format(\n",
    "        name,\n",
    "        score.mean(),\n",
    "        score.var()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_concat.to_csv('ImputedData', ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
